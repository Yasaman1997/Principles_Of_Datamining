{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "import math\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-575ff3ea7508>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-575ff3ea7508>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'x'"
     ]
    }
   ],
   "source": [
    "#train=pd.read_csv('noisy_train.csv')\n",
    "\n",
    "f = open('noisy_train.csv',\"r\")\n",
    "reader = csv.reader(f)\n",
    "data = []\n",
    "rownum=0\n",
    "\n",
    "for row in reader:\n",
    "    if(rownum == 0):\n",
    "        header = row\n",
    "        rownum = rownum+1\n",
    "    else:\n",
    "        if any(row):\n",
    "            row = [int(i) for i in row]\n",
    "            data.append(dict(zip(header,row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdataset(train): \n",
    "    \n",
    "    X_1=train.drop('poisonous',axis=1)\n",
    "    Y_1=train['poisonous']\n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_1, Y_1, test_size = 0.2, random_state = 100)\n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEntropy(data,attr):\n",
    "    count = {}\n",
    "    \n",
    "        for i in data: \n",
    "            if(i[attr] in count):\n",
    "                count[i[attr]] = count[i[attr]]+1\n",
    "            else:\n",
    "                count[i[attr]]=1\n",
    "    h=0.0   \n",
    "    for j in count.values():\n",
    "        h= h+ ((-1)*(j/len(data))* math.log2(j/len(data)))\n",
    "    return h\n",
    "\n",
    "def calculateIG(data,attr,classLabel):\n",
    "    countsInSplit = {}\n",
    "    entropyBefore = calculateEntropy(data,classLabel)\n",
    "    entropyAfter = 0.0  \n",
    "    for i in data:\n",
    "        if(i[attr] in countsInSplit):\n",
    "            countsInSplit[i[attr]] = countsInSplit[i[attr]]+1\n",
    "        else:\n",
    "            countsInSplit[i[attr]]=1\n",
    "     \n",
    "    for valOfAttr in countsInSplit:\n",
    "        subdata = [r for r in data if(r[attr] == valOfAttr)]\n",
    "        entropyAfter = entropyAfter + ((countsInSplit[valOfAttr]/sum(countsInSplit.values()))* calculateEntropy(subdata,classLabel))\n",
    "    return entropyBefore-entropyAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestAttribute(data,header,classLabel):\n",
    "    data = data[:]\n",
    "    \n",
    "    for testAttr in header:\n",
    "        if(testAttr == header[len(header)-1]):\n",
    "            continue\n",
    "        maxIG =0.0\n",
    "        attr = \"\"\n",
    "        IG = calculateIG(data,testAttr,header[len(header)-1])\n",
    "        if(IG>maxIG):\n",
    "            maxIG=IG\n",
    "            attr = testAttr\n",
    "    return attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb  5 00:36:26 2018\n",
    "@author: Deepesh\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Feb  3 01:10:29 2018\n",
    "@author: Deepesh\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def calculateEntropy(data,attr):\n",
    "    count = {}\n",
    "    \n",
    "    for i in data: \n",
    "        if(i[attr] in count):\n",
    "            count[i[attr]] = count[i[attr]]+1\n",
    "        else:\n",
    "            count[i[attr]]=1\n",
    "    h=0.0   \n",
    "    for j in count.values():\n",
    "        h= h+ ((-1)*(j/len(data))* math.log2(j/len(data)))\n",
    "    return h\n",
    "\n",
    "def calculateIG(data,attr,classLabel):\n",
    "    countsInSplit = {}\n",
    "    entropyBefore = calculateEntropy(data,classLabel)\n",
    "    entropyAfter = 0.0  \n",
    "    for i in data:\n",
    "        if(i[attr] in countsInSplit):\n",
    "            countsInSplit[i[attr]] = countsInSplit[i[attr]]+1\n",
    "        else:\n",
    "            countsInSplit[i[attr]]=1\n",
    "     \n",
    "    for valOfAttr in countsInSplit:\n",
    "        subdata = [r for r in data if(r[attr] == valOfAttr)]\n",
    "        entropyAfter = entropyAfter + ((countsInSplit[valOfAttr]/sum(countsInSplit.values()))* calculateEntropy(subdata,classLabel))\n",
    "    return entropyBefore-entropyAfter\n",
    "\n",
    "def bestAttribute(data,header,classLabel):\n",
    "    data = data[:]\n",
    "    \n",
    "    for testAttr in header:\n",
    "        if(testAttr == header[len(header)-1]):\n",
    "            continue\n",
    "        maxIG =0.0\n",
    "        attr = \"\"\n",
    "        IG = calculateIG(data,testAttr,header[len(header)-1])\n",
    "        if(IG>maxIG):\n",
    "            maxIG=IG\n",
    "            attr = testAttr\n",
    "    return attr\n",
    "\n",
    "\n",
    "#print(\"Max IG = {} for attribute = {}\".format(maxIG,attr))\n",
    "\n",
    "trainFile = \"D:\\\\MyStudy\\\\UTD\\\\sem2\\\\ML\\\\Assignment\\\\assign 2\\\\training_set - Copy.csv\"\n",
    "\n",
    "f = open(trainFile,\"r\")\n",
    "reader = csv.reader(f)\n",
    "data = []\n",
    "rownum=0\n",
    "\n",
    "for row in reader:\n",
    "    if(rownum == 0):\n",
    "        header = row\n",
    "        rownum = rownum+1\n",
    "    else:\n",
    "        if any(row):\n",
    "            row = [int(i) for i in row]\n",
    "            data.append(dict(zip(header,row)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
