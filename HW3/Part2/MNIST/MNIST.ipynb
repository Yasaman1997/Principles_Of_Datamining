{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "pCazZhu5Ltva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.factorization import KMeans\n",
        "\n",
        "# Ignore all GPUs, tf random forest does not benefit from it.\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qiy4RigXL09h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "4f8cbaa1-9eb3-4fb0-b6d2-4148d0a439aa"
      },
      "cell_type": "code",
      "source": [
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "full_data_x = mnist.train.images"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-d1701dded223>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "82ZHFzS9L52U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_steps = 50 # Total steps to train\n",
        "batch_size = 1024 # The number of samples per batch\n",
        "k = 25 # The number of clusters\n",
        "num_classes = 10 # The 10 digits\n",
        "num_features = 784 # Each image is 28x28 pixels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VL5hJUbkMD1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input images\n",
        "X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
        "# Labels (for assigning a label to a centroid and testing)\n",
        "Y = tf.placeholder(tf.float32, shape=[None, num_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyIh5H5fMMlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K-Means Parameters\n",
        "kmeans = KMeans(inputs=X, num_clusters=k, distance_metric='cosine',\n",
        "                use_mini_batch=True)\n",
        "\n",
        "# Build KMeans graph\n",
        "training_graph = kmeans.training_graph()\n",
        "\n",
        "if len(training_graph) > 6: # Tensorflow 1.4+\n",
        "    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n",
        "     cluster_centers_var, init_op, train_op) = training_graph\n",
        "else:\n",
        "    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n",
        "     init_op, train_op) = training_graph\n",
        "\n",
        "cluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\n",
        "avg_distance = tf.reduce_mean(scores)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YWOHX6VeMQiM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0caf5b41-b53f-4a9f-c182-e4e6063e7d7e"
      },
      "cell_type": "code",
      "source": [
        "# Initialize the variables (i.e. assign their default value)\n",
        "init_vars = tf.global_variables_initializer()\n",
        "\n",
        "# Start TensorFlow session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Run the initializer\n",
        "sess.run(init_vars, feed_dict={X: full_data_x})\n",
        "sess.run(init_op, feed_dict={X: full_data_x})\n",
        "\n",
        "# Training\n",
        "for i in range(1, num_steps + 1):\n",
        "    _, d, idx = sess.run([train_op, avg_distance, cluster_idx],\n",
        "                         feed_dict={X: full_data_x})\n",
        "    if i % 10 == 0 or i == 1:\n",
        "        print(\"Step %i, Avg Distance: %f\" % (i, d))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Avg Distance: 0.341471\n",
            "Step 10, Avg Distance: 0.221609\n",
            "Step 20, Avg Distance: 0.220328\n",
            "Step 30, Avg Distance: 0.219776\n",
            "Step 40, Avg Distance: 0.219419\n",
            "Step 50, Avg Distance: 0.219154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C_jL4t3wMfP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6269ce9a-4356-4da7-ca50-58333b314f10"
      },
      "cell_type": "code",
      "source": [
        "# Assign a label to each centroid\n",
        "# Count total number of labels per centroid, using the label of each training\n",
        "# sample to their closest centroid (given by 'idx')\n",
        "counts = np.zeros(shape=(k, num_classes))\n",
        "for i in range(len(idx)):\n",
        "    counts[idx[i]] += mnist.train.labels[i]\n",
        "# Assign the most frequent label to the centroid\n",
        "labels_map = [np.argmax(c) for c in counts]\n",
        "labels_map = tf.convert_to_tensor(labels_map)\n",
        "\n",
        "# Evaluation ops\n",
        "# Lookup: centroid_id -> label\n",
        "cluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n",
        "# Compute accuracy\n",
        "correct_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\n",
        "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Test Model\n",
        "test_x, test_y = mnist.test.images, mnist.test.labels\n",
        "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7dbtdcCMu02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#My Implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YsSacIsLM5E7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "60b3391e-0ac7-42b4-8d3f-a67eb46b013b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N=10000\n",
        "K=4\n",
        "MAX_ITERS = 1000\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "points = tf.Variable(tf.random_uniform([N,2]))\n",
        "cluster_assignments = tf.Variable(tf.zeros([N], dtype=tf.int64))\n",
        "\n",
        "# Silly initialization:  Use the first two points as the starting                \n",
        "# centroids.  In the real world, do this better.                                 \n",
        "centroids = tf.Variable(tf.slice(points.initialized_value(), [0,0], [K,2]))\n",
        "\n",
        "# Replicate to N copies of each centroid and K copies of each                    \n",
        "# point, then subtract and compute the sum of squared distances.                 \n",
        "rep_centroids = tf.reshape(tf.tile(centroids, [N, 1]), [N, K, 2])\n",
        "rep_points = tf.reshape(tf.tile(points, [1, K]), [N, K, 2])\n",
        "sum_squares = tf.reduce_sum(tf.square(rep_points - rep_centroids),\n",
        "                            reduction_indices=2)\n",
        "\n",
        "# Use argmin to select the lowest-distance point                                 \n",
        "best_centroids = tf.argmin(sum_squares, 1)\n",
        "did_assignments_change = tf.reduce_any(tf.not_equal(best_centroids,\n",
        "                                                    cluster_assignments))\n",
        "\n",
        "def bucket_mean(data, bucket_ids, num_buckets):\n",
        "    total = tf.unsorted_segment_sum(data, bucket_ids, num_buckets)\n",
        "    count = tf.unsorted_segment_sum(tf.ones_like(data), bucket_ids, num_buckets)\n",
        "    return total / count\n",
        "\n",
        "means = bucket_mean(points, best_centroids, K)\n",
        "\n",
        "# Do not write to the assigned clusters variable until after                     \n",
        "# computing whether the assignments have changed - hence with_dependencies\n",
        "with tf.control_dependencies([did_assignments_change]):\n",
        "    do_updates = tf.group(\n",
        "        centroids.assign(means),\n",
        "        cluster_assignments.assign(best_centroids))\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.initialize_all_variables())\n",
        "\n",
        "changed = True\n",
        "iters = 0\n",
        "\n",
        "while changed and iters < MAX_ITERS:\n",
        "    iters += 1\n",
        "    [changed, _] = sess.run([did_assignments_change, do_updates])\n",
        "\n",
        "[centers, assignments] = sess.run([centroids, cluster_assignments])\n",
        "end = time.time()\n",
        "print (\"Found in %.2f seconds\" % (end-start)), iters, \"iterations\"\n",
        "print (\"Centroids:\")\n",
        "print (centers)\n",
        "print (\"Cluster assignments:\", assignments)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Found in 1.42 seconds\n",
            "Centroids:\n",
            "[[0.24934164 0.7524118 ]\n",
            " [0.748052   0.74306476]\n",
            " [0.7531253  0.24525188]\n",
            " [0.2548147  0.25740138]]\n",
            "Cluster assignments: [1 2 2 ... 3 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1_Z-WB5GM5tX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "outputId": "97b8a0cf-f8fe-46bb-d247-3faa8b005f4b"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-0bebacae269b>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting model_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting model_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting model_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting model_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0bebacae269b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Executing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Print Accuracy of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xIDGue0EOTaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7328cd80-1a4c-4722-c39d-802c3481f879"
      },
      "cell_type": "code",
      "source": [
        "\"\"\" K-Means.\n",
        "Implement K-Means algorithm with TensorFlow, and apply it to classify\n",
        "handwritten digit images. This example is using the MNIST database of\n",
        "handwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n",
        "Note: This example requires TensorFlow v1.1.0 or over.\n",
        "Author: Aymeric Damien\n",
        "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.factorization import KMeans\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# Ignore all GPUs, tf random forest does not benefit from it.\n",
        "#import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "full_data_x = mnist.train.images\n",
        "\n",
        "# Parameters\n",
        "num_steps = 50 # Total steps to train\n",
        "batch_size = 1024 # The number of samples per batch\n",
        "k = 78 # The number of clusters\n",
        "num_classes = 10 # The 10 digits\n",
        "num_features = 784 # Each image is 28x28 pixels\n",
        "\n",
        "# Input images\n",
        "X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
        "# Labels (for assigning a label to a centroid and testing)\n",
        "Y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
        "\n",
        "# K-Means Parameters\n",
        "kmeans = KMeans(inputs=X, num_clusters=k, distance_metric='cosine',use_mini_batch=True)\n",
        "\n",
        "# Build KMeans graph\n",
        "training_graph = kmeans.training_graph()\n",
        "\n",
        "if len(training_graph) > 6: \n",
        "    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n",
        "     cluster_centers_var, init_op, train_op) = training_graph\n",
        "else:\n",
        "    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n",
        "     init_op, train_op) = training_graph\n",
        "\n",
        "cluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\n",
        "avg_distance = tf.reduce_mean(scores)\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init_vars = tf.global_variables_initializer()\n",
        "\n",
        "# Start TensorFlow session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Run the initializer\n",
        "sess.run(init_vars, feed_dict={X: full_data_x})\n",
        "sess.run(init_op, feed_dict={X: full_data_x})\n",
        "\n",
        "\n",
        "# Training\n",
        "for i in range(1, num_steps + 1):\n",
        "    _, d, idx = sess.run([train_op, avg_distance, cluster_idx],\n",
        "                         feed_dict={X: full_data_x})\n",
        "    if i % 10 == 0 or i == 1:\n",
        "        print(\"Step %i, Avg Distance: %f\" % (i, d))\n",
        "\n",
        "# Assign a label to each centroid\n",
        "# Count total number of labels per centroid, using the label of each training\n",
        "# sample to their closest centroid (given by 'idx')\n",
        "counts = np.zeros(shape=(k, num_classes))\n",
        "\n",
        "for i in range(len(idx)):\n",
        "    counts[idx[i]] += mnist.train.labels[i]\n",
        "# Assign the most frequent label to the centroid\n",
        "labels_map = [np.argmax(c) for c in counts]\n",
        "labels_map = tf.convert_to_tensor(labels_map)\n",
        "\n",
        "# Evaluation ops\n",
        "# Lookup: centroid_id -> label\n",
        "cluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n",
        "\n",
        "# Compute accuracy\n",
        "correct_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\n",
        "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Test Model\n",
        "test_x, test_y = mnist.test.images, mnist.test.labels\n",
        "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "Step 1, Avg Distance: 0.284920\n",
            "Step 10, Avg Distance: 0.184646\n",
            "Step 20, Avg Distance: 0.183262\n",
            "Step 30, Avg Distance: 0.182651\n",
            "Step 40, Avg Distance: 0.182276\n",
            "Step 50, Avg Distance: 0.182016\n",
            "Test Accuracy: 0.8375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Lij6J8pP-JQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMqRmlz_Twgl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}