{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'megprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f37bf8af66e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmegprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'megprocess'"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from megprocess import *\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "def entropy(counts):\n",
    "    '''Compute entropy.'''\n",
    "    ps = counts/float(sum(counts))  # coerce to float and normalize\n",
    "    ps = ps[nonzero(ps)]            # toss out zeros\n",
    "    H = -sum(ps * numpy.log2(ps))   # compute entropy\n",
    "    \n",
    "    return H\n",
    "\n",
    "def mi(x, y, bins):\n",
    "    '''Compute mutual information'''\n",
    "    counts_xy = histogram2d(x, y, bins=bins, range=[[0, 311335], [0, 311335]])[0]\n",
    "    counts_x  = histogram(  x,    bins=bins, range=[0, 311335])[0]\n",
    "    counts_y  = histogram(  y,    bins=bins, range=[0, 311335])[0]\n",
    "    \n",
    "    H_xy = entropy(counts_xy)\n",
    "    H_x  = entropy(counts_x)\n",
    "    H_y  = entropy(counts_y)\n",
    "    \n",
    "    return H_x + H_y - H_xy\n",
    "\n",
    "def mirror(data):\n",
    "    n_chan = shape(data)[0]\n",
    "    for c1 in range(n_chan):\n",
    "        for c2 in range(n_chan):\n",
    "            if c1 > c2:\n",
    "                data[c1,c2] = data[c2,c1]\n",
    "                data[c1,c2] = data[c2,c1]\n",
    "    return data\n",
    "\n",
    "def cross_mi(epochs, interest_region, n_chan, bins):\n",
    "    mi_ldif = zeros((n_chan, n_chan))\n",
    "    mi_dlif = zeros((n_chan, n_chan))\n",
    "    for ch1 in range(n_chan):\n",
    "        print (ch1)\n",
    "        for ch2 in range(n_chan):\n",
    "            if ch2 >= ch1:\n",
    "                ldif_a = epochs[7,interest_region,ch1,:].flatten()\n",
    "                ldif_b = epochs[7,interest_region,ch2,:].flatten()\n",
    "                dlif_a = epochs[3,interest_region,ch1,:].flatten()\n",
    "                dlif_b = epochs[3,interest_region,ch2,:].flatten()\n",
    "                mi_ldif[ch1, ch2] = mi(ldif_a, ldif_b, bins=bins)\n",
    "                mi_dlif[ch1, ch2] = mi(dlif_a, dlif_b, bins=bins)\n",
    "    return mirror(mi_ldif), mirror(mi_dlif)\n",
    "\n",
    "def auto_mi(epochs, total_offset, interest_region, n_chan, bins):\n",
    "    ami_ldif = zeros((n_chan, total_offset))\n",
    "    ami_dlif = zeros((n_chan, total_offset))\n",
    "    for ch in range(n_chan):\n",
    "        print (ch)\n",
    "        for tau in range(total_offset):\n",
    "            ldif_a = epochs[7, interest_region,     ch, :].flatten()\n",
    "            ldif_b = epochs[7, interest_region+tau, ch, :].flatten()\n",
    "            dlif_a = epochs[3, interest_region,     ch, :].flatten()\n",
    "            dlif_b = epochs[3, interest_region+tau, ch, :].flatten()\n",
    "            ami_ldif[ch, tau] = mi(ldif_a, ldif_b, bins=bins)\n",
    "            ami_dlif[ch, tau] = mi(dlif_a, dlif_b, bins=bins)\n",
    "    return ami_ldif, ami_dlif\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    epochs = numpy.load(\"epochs.npy\")\n",
    "    \n",
    "    import psyco\n",
    "    histogram2d = psyco.proxy(numpy.histogram2d)\n",
    "    \n",
    "    # Transform the data to emphasize power. \n",
    "    # This is something to play around with.\n",
    "    epochs = abs(epochs)**2 \n",
    "    \n",
    "    # Constants.\n",
    "    bins = 64\n",
    "    n_chan = 157\n",
    "    total_offset = 150\n",
    "    interest_region = arange(250, 450+1)\n",
    "    \n",
    "    print (\"Computing cross mutual information\")\n",
    "    mi_ldif, mi_dlif = cross_mi(epochs, interest_region, n_chan, bins)\n",
    "    \n",
    "    #print \"Computing auto mutual information with time shifts\"\n",
    "    #ami_ldif, ami_dlif = auto_mi(epochs, total_offset, interest_region, n_chan, bins)\n",
    "        \n",
    "    savez(\"midata.npz\", mi_ldif, mi_dlif)#, ami_ldif, ami_dlif)\n",
    "        \n",
    "    figure(1)\n",
    "    imshow(mi_ldif, interpolation=\"nearest\", origin=\"lower\")\n",
    "    colorbar()                                             \n",
    "    title(\"Ungrammatical condition\")                       \n",
    "    xlabel(\"Channels\")                                     \n",
    "    ylabel(\"Channels\")                                     \n",
    "                                                           \n",
    "    figure(2)                                              \n",
    "    imshow(mi_dlif, interpolation=\"nearest\", origin=\"lower\")\n",
    "    colorbar()\n",
    "    title(\"Grammatical condition\")\n",
    "    xlabel(\"Channels\")\n",
    "    ylabel(\"Channels\")\n",
    "    \n",
    "    #mi_means_ldif = zeros(n_chan)\n",
    "    #mi_means_dlif = zeros(n_chan)\n",
    "    #for ch in arange(n_chan):\n",
    "    #    mi_means_ldif[ch] = mean(mi_ldif[ch, :])\n",
    "    #    mi_means_dlif[ch] = mean(mi_dlif[ch, :])\n",
    "    #\n",
    "    #figure(3)\n",
    "    #bar(range(n_chan), mi_means_ldif)\n",
    "    #sorted_chans_ldif = argsort(mi_means_ldif)\n",
    "    #best = sorted_chans_ldif[-1]\n",
    "    #print \"ldif\", sorted_chans_ldif\n",
    "    #\n",
    "    #figure(4)\n",
    "    #bar(range(n_chan), mi_means_dlif)\n",
    "    #sorted_chans_dlif = argsort(mi_means_dlif)\n",
    "    #best = sorted_chans_dlif[-1]\n",
    "    #print \"dlif\", sorted_chans_dlif\n",
    "    #\n",
    "    #\n",
    "    ##\n",
    " \n",
    "            \n",
    "    #figure(5)\n",
    "    #plot(offsets, mi_phase_ldif, 'o', label=\"Ungrammatical\")\n",
    "    #plot(offsets, mi_phase_dlif, 'o', label=\"Grammatical\")\n",
    "    #axis('tight')\n",
    "    #title(\"Time-shifted auto-mutual information\")\n",
    "    #xlabel(\"Time shift (ms)\")\n",
    "    #ylabel(\"Mutual information\")\n",
    "    #legend(loc=2)\n",
    "    #\n",
    "    #print \"ldif = \", mi_ldif[best,:]\n",
    "    #print \"dlif = \", mi_dlif[best,:]\n",
    "    \n",
    "    #print \"ldif = \", mi_ldif[19,:]\n",
    "    #print \"dlif = \", mi_dlif[19,:]\n",
    "    \n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
